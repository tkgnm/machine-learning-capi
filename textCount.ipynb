{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below line to install the requirements\n",
    "# pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np     \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    " \n",
    "We have five JSON files to parse. Each file is a batch of articles and their associated metadata from The Guardian's Content API (CAPI). With a free developer key, we are limited to only 200 articles per request. With a total of five downloads, this brings the total to 1000 on which we can use. If you'd like to query the API yourself, this repo contains an example query in a .txt file. You can sign up for your own developer key at https://open-platform.theguardian.com/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JSON files contain many fields that could be useful for the purposes of machine learning. However, we will focus on the following fields for now:\n",
    "\n",
    "- trailtext \n",
    "- headline\n",
    "- body (this is the data we will use for machine learning, the above two merely provide context)\n",
    "\n",
    "We can experiment with the metadata later (such as tags, author etc). Let's initialise our arrays and append with each article's relevant field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"search_0.json\", \"search_1.json\", \"search_2.json\", \"search_3.json\", \"search_4.json\"]\n",
    "\n",
    "headline = []\n",
    "trailText = []\n",
    "body = []\n",
    "\n",
    "for file in files:\n",
    "        \n",
    "    # Opening JSON file\n",
    "    f = open(\"articles/\" + file)\n",
    "    \n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "        \n",
    "    #this is the data that we actually care about\n",
    "    articles = data['response']['results']\n",
    "\n",
    "    for i in range(len(articles)):\n",
    "        headline.append((articles[i][\"fields\"][\"headline\"]))\n",
    "        trailText.append((articles[i][\"fields\"][\"trailText\"]))\n",
    "        body.append((articles[i][\"fields\"][\"body\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check the lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headline), len(trailText), len(body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "We should now clean the data as some of the fields contain HTML (which we don't want). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlRemover = re.compile('<.*?>') \n",
    "newlineRemover = '\\n'\n",
    "\n",
    "# as per recommendation from @freylis, compile once only\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(htmlRemover, '', raw_html)\n",
    "    cleantext = re.sub(newlineRemover, '', cleantext)\n",
    "    return cleantext\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanTrailText = []\n",
    "cleanBody = []\n",
    "\n",
    "for i in range(len(body)):\n",
    "    cleanTrailText.append(cleanhtml(trailText[i]))\n",
    "    cleanBody.append(cleanhtml(body[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanBody[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the articles into a sparse matrix based on similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first ofcourse, we need to perform a tf-idf transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=1, stop_words=\"english\")                                                                                                                                                                                                   \n",
    "tfidf = vect.fit_transform(cleanBody)                                                                                                                                                                                                                       \n",
    "pairwise_similarity = tfidf * tfidf.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x40735 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 339334 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary for ensuring we don't just return the same article\n",
    "arr = pairwise_similarity.toarray()     \n",
    "np.fill_diagonal(arr, np.nan)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did it work? Let's find out!\n",
    "\n",
    "Let's draw 10 random articles and find the most similar for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "SAVE FOR LATER ARTICLE: Dave Brailsford recruited to Andrew Strauss’s review of English cricket\n",
      "Andrew Strauss has recruited Sir Dave Brailsford, the former performance director of British Cycling and current director of sport at Ineos, to his high performance review of English cricket\n",
      "\n",
      "\n",
      "RECOMMENDED ARTICLE: Millions of dollars are flowing into US cricket. But is there a market for the sport?\n",
      "America is the largest sports market in the world. But can cricket really establish a foothold where others have failed?\n",
      "Similarity score: 0.227\n",
      "___________\n",
      "2:\n",
      "SAVE FOR LATER ARTICLE: Zelenskiy urges ‘maximum sanctions’ against Russia in Davos speech\n",
      "Ukrainian president tells business leaders they need to decide whether ‘brute force’ should rule the world\n",
      "\n",
      "\n",
      "RECOMMENDED ARTICLE: Davos day one: Zelenskiy calls for maximum sanctions against Russia; recession fears on the rise – business live\n",
      "Rolling coverage of the first day of the World Economic Forum in Davos\n",
      "Similarity score: 0.529\n",
      "___________\n",
      "3:\n",
      "SAVE FOR LATER ARTICLE: Nationals could dump Barnaby Joyce over net zero stance with Peter Dutton set to lead Liberals\n",
      "Sussan Ley or Jane Hume likely to be deputy Liberal leader as Coalition continues to grapple with election fallout\n",
      "\n",
      "\n",
      "RECOMMENDED ARTICLE: PM has ‘frank and very positive’ call with Johnson – as it happend\n",
      "This blog is now closed\n",
      "Similarity score: 0.418\n",
      "___________\n",
      "4:\n",
      "SAVE FOR LATER ARTICLE: Facebook whistleblowers allege Meta may have breached Australia’s foreign interference laws \n",
      "Company accused of deliberately blocking Australian government pages as a negotiating tactic during debate over news media laws\n",
      "\n",
      "\n",
      "RECOMMENDED ARTICLE: Rod Sims says Facebook should be forced to negotiate with SBS under news media bargaining code\n",
      "Despite dozens of deals to pay Australian news publishers for content, social media company has left out SBS and the Conversation\n",
      "Similarity score: 0.455\n",
      "___________\n",
      "5:\n",
      "SAVE FOR LATER ARTICLE: Biden is sending dangerous messages about Taiwan to China. The US should tread with care\n",
      "Remarks like this feed China’s anxiety that US commitment to its One China policy is slipping\n",
      "\n",
      "\n",
      "RECOMMENDED ARTICLE: Fears Biden’s Taiwan comments may raise tensions despite rowback\n",
      "President said US would ‘get involved ’ if China attacked Taiwan, which some saw as policy shift\n",
      "Similarity score: 0.575\n",
      "___________\n",
      "6:\n",
      "SAVE FOR LATER ARTICLE: First Thing: Texas gunman was inside school for 40 minutes\n",
      "More information has emerged on the deadly school shooting, including a timeline. Plus, Walmart apologizes for selling Juneteenth-themed ice-cream\n",
      "\n",
      "\n",
      "RECOMMENDED ARTICLE:  Texas school shooting: gunman was inside for 40 minutes, officials say – updates as they happened\n",
      "Texas governor and local officials share more details about the shooting at the Robb elementary school in Uvalde\n",
      "Similarity score: 0.333\n",
      "___________\n",
      "7:\n",
      "SAVE FOR LATER ARTICLE: Self-reflection is usually for leftists and the weak but we need to find out who to blame for the election\n",
      "There’s no time for dramatics because democracy has been MURDERED!\n",
      "\n",
      "\n",
      "RECOMMENDED ARTICLE: French Open 2022: Swiatek in action, Jeanjean stuns Pliskova, Medvedev through – live!\n",
      "Join John Brewin for all the action on day five at Roland Garros\n",
      "Similarity score: 0.0\n",
      "___________\n",
      "8:\n",
      "SAVE FOR LATER ARTICLE: Harry Styles: Harry’s House review – shimmering, in-the-mood melodies\n",
      "An accomplished follow-up to his Grammy-winning second album, this is a light-footed strut around sex, drugs and fine wine\n",
      "\n",
      "\n",
      "RECOMMENDED ARTICLE: When Harry met Harry! The man who put Harry Styles in a dress\n",
      "Stylist Harry Lambert is behind the singer’s subversive, androgynous style and Emma Corrin’s balloon bra, and has even convinced football clients to carry glittery pink handbags. He explains why fashion for men is changing\n",
      "Similarity score: 0.167\n",
      "___________\n",
      "9:\n",
      "SAVE FOR LATER ARTICLE: Sir Angus Grossart obituary\n",
      "Prominent Scottish merchant banker who was a dedicated promoter of cultural life and the arts in his homeland\n",
      "\n",
      "\n",
      "RECOMMENDED ARTICLE: Boris Johnson to try to oust Lady Scotland from Commonwealth role\n",
      "PM accused of abuse of position with public backing for Jamaican candidate before summit next month\n",
      "Similarity score: 0.129\n",
      "___________\n"
     ]
    }
   ],
   "source": [
    "for x in range(1, 10):\n",
    "\n",
    "    i = random.randint(0,1000)                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "\n",
    "    input_doc = cleanBody[i]                                                                                                                                                                                                 \n",
    "    input_idx = cleanBody.index(input_doc)                                                                                                                                                                                                                      \n",
    "    input_idx                                                                                                                                                                                                                                              \n",
    "    result_idx = np.nanargmax(arr[input_idx]) \n",
    "    print(\"{}:\".format(x))\n",
    "    print(\"SAVE FOR LATER ARTICLE: {}\".format(headline[i]))\n",
    "    print(\"{}\".format(trailText[i]))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    # print(\"cleanBody[result_idx]   \n",
    "\n",
    "    print(\"RECOMMENDED ARTICLE: {}\".format(headline[result_idx]))\n",
    "    print(\"{}\".format(trailText[result_idx]))\n",
    "    similarity_score = round(arr[input_idx,result_idx], 3)\n",
    "    print(\"Similarity score: {}\".format(similarity_score))\n",
    "    print(\"___________\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7d5f047caa9781d537157614e3e4bf0ff375ed37ad5b7d2efb2a07d188de358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
